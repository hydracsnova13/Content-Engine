# Content-Engine

- This repository contains the code to run your own custom content engine, please follow the instructions given below strictly in order to get smooth operation of the software:
   
- First make sure you have the ollama installed from the link https://ollama.com/download/windows

- After installation of ollama, for this project we have to install 2 models on the ollama server, the enbedding model "nomic-embed-text" and the LLM "mistral" 

- To install "nomic-embed-text", type "ollama pull nomic-embed-text"
- To install "mistral", type "ollama pull mistral"

- You have to wait for both of them to complete installing, it might take somewhere from 3 minutes to 30 minutes depending on your systems specs

- After installation, you can check the models in your ollama by typing: "ollama list"

- After you verify your models, its time to launch the server by using the command: "ollama serve"

- 
